# Zidio_Project on Audio Speech Emotion Recognition
It is a Data Science Project on Audio Speech Emotion Recognition.
Kaggle TESS speech emotion dataset is used to trained the model and applied on unseen data manually collected and generated by me.
Training audio dataset link: https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess .
1800 audio files of various speakers with 7 types of emotions (angry,disgust,fear,happy,neutral,surprise,sad) are stored in the dataset.
44 Feautures are extracted from each audio files which including 40 MFCC features,Mean Pitch,Mean Energy, HNR(Harmonics to Noise Ratio),ZCR(Zero Crossing Rate) to make the structured data for the model.
Global and local outliers are removed with the help of zscore and LocalOutlierFactor methods of stat and sklearn module respectively.
The model is built using LSTM algorithm and applies 50 epochs with batch size = 64 to train the model.
The trained model has accuracy of 95% approx and saved the model as a keras file.
Later the model is applied on unseen data to and predict emotion of the audio speech.
